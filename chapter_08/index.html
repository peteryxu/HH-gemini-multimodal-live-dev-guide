<!DOCTYPE html>
<html>
<head>
  <title>Gemini Audio-to-Audio WebSocket Demo</title>
  <link rel="stylesheet" href="style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
</head>
<body>
  <div class="controls">
    <button id="micButton" onclick="toggleMicrophone()" disabled>
      <span class="material-symbols-outlined">play_arrow</span>
    </button>
    <button id="webcamButton" onclick="toggleWebcam()" class="action-button">
      <span class="material-symbols-outlined">videocam</span>
    </button>
    <button id="switchCameraButton" onclick="switchCamera()" class="action-button hidden">
      <span class="material-symbols-outlined">flip_camera_ios</span>
    </button>
  </div>
  <div id="functionInfo" class="function-info">
    Waiting for function calls...
  </div>
  <div class="video-container">
    <video id="videoPreview" autoplay playsinline class="hidden"></video>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script type="module">
    import { base64ToArrayBuffer, updateFunctionInfo } from './utils.js';
    import { AudioRecorder } from './audio-recorder.js';
    import { AudioStreamer } from './audio-streamer.js';
    import { MediaHandler } from './media-handler.js';
    import { getWeather } from './weather-api.js';
    import { statusHandler } from './status-handler.js';

    console.log('Script started, setting up WebSocket...');
    const apiKey = '<YOUR_API_KEY>';
    const host = 'generativelanguage.googleapis.com';
    const endpoint = `wss://${host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key=${apiKey}`;

    const ws = new WebSocket(endpoint);
    let audioContext;
    let audioStreamer;
    let audioRecorder;
    let isRecording = false;
    let initialized = false;
    let isInterrupted = false;
    let mediaHandler;

    document.addEventListener('DOMContentLoaded', () => {
      console.log('DOM loaded, initializing media handler');
      mediaHandler = new MediaHandler();
      const videoElement = document.getElementById('videoPreview');
      if (!videoElement) {
        console.error('Video element not found!');
        return;
      }
      mediaHandler.initialize(videoElement);
    });

    async function ensureAudioInitialized() {
      if (!initialized) {
        try {
          console.log('Initializing audio context...');
          audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
          console.log('Audio context state:', audioContext.state);
          
          if (audioContext.state === 'suspended') {
            console.log('Resuming suspended audio context...');
            await audioContext.resume();
            console.log('Audio context resumed, new state:', audioContext.state);
          }
          
          console.log('Creating audio streamer...');
          audioStreamer = new AudioStreamer(audioContext);
          initialized = true;
          console.log('Audio initialization complete');
          return true;
        } catch (error) {
          console.error('Audio initialization failed:', error);
          return false;
        }
      }
      return true;
    }

    async function playAudioChunk(base64AudioChunk) {
      try {
        console.log('Attempting to play audio chunk...');
        if (!await ensureAudioInitialized()) {
          console.error('Failed to initialize audio');
          return;
        }
        
        const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
        const uint8Array = new Uint8Array(arrayBuffer);
        console.log('Adding PCM data to streamer, length:', uint8Array.length);
        audioStreamer.addPCM16(uint8Array);
        const playbackState = audioStreamer.resume();
        console.log('Audio playback resumed, streamer state:', playbackState);
      } catch (error) {
        console.error('Error playing audio chunk:', error, error.stack);
      }
    }

    async function startRecording() {
      try {
        console.log('Starting recording...');
        if (!await ensureAudioInitialized()) return;
        
        // Reset state when starting new recording
        isInterrupted = false;
        if (audioStreamer) {
          console.log('Stopping previous audio streamer');
          audioStreamer.stop();
        }

        console.log('Creating new audio recorder');
        audioRecorder = new AudioRecorder();
        await audioRecorder.start();

        audioRecorder.on('data', (base64Data) => {
          console.log('Got audio data, length:', base64Data.length);
          if (ws.readyState === WebSocket.OPEN) {
            sendAudioChunk(base64Data);
          } else {
            console.warn('WebSocket not open, state:', ws.readyState);
          }
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">stop</span>';
        console.log('Recording started successfully');
      } catch (error) {
        console.error('Error starting recording:', error);
      }
    }

    function stopRecording() {
      if (audioRecorder) {
        console.log('Stopping recording...');
        audioRecorder.stop();
        audioRecorder.off('data');
        isRecording = false;
        document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">play_arrow</span>';
        
        // Stop video streams when stopping recording
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = '<span class="material-symbols-outlined">videocam</span>';
        
        if (ws.readyState === WebSocket.OPEN) {
          sendEndMessage();
        }
        console.log('Recording stopped');
      }
    }

    function sendAudioChunk(base64Audio) {
      const message = {
        realtime_input: {
          media_chunks: [{
            mime_type: "audio/pcm",
            data: base64Audio
          }]
        }
      };
      console.log('Sending audio chunk to server');
      ws.send(JSON.stringify(message));
    }

    function sendVideoFrame(base64Image) {
      const message = {
        realtimeInput: {
          mediaChunks: [{
            mime_type: "image/jpeg",
            data: base64Image
          }]
        }
      };
      console.log('Sending video frame to server');
      ws.send(JSON.stringify(message));
    }

    function sendEndMessage() {
      const message = {
        client_content: {
          turns: [{
            role: "user",
            parts: []
          }],
          turn_complete: true
        }
      };
      console.log('Sending end message to server');
      ws.send(JSON.stringify(message));
    }

    function sendContinueSignal() {
      const message = {
        client_content: {
          turns: [{
            role: "user",
            parts: []
          }],
          turn_complete: false
        }
      };
      console.log('Sending continue signal');
      ws.send(JSON.stringify(message));
    }

    window.toggleMicrophone = function() {
      console.log('Toggle microphone, current state:', isRecording);
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    window.toggleWebcam = async function() {
      console.log('Toggle webcam, current state:', mediaHandler.isWebcamActive);
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = '<span class="material-symbols-outlined">videocam</span>';
        document.getElementById('switchCameraButton').classList.add('hidden');
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = '<span class="material-symbols-outlined">videocam_off</span>';
          // Only show camera switch button on mobile devices
          if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
            document.getElementById('switchCameraButton').classList.remove('hidden');
          }
          mediaHandler.startFrameCapture((base64Image) => {
            if (ws && ws.readyState === WebSocket.OPEN) {
              sendVideoFrame(base64Image);
            }
          });
        }
      }
    };

    window.switchCamera = async function() {
      await mediaHandler.switchCamera();
    };

    ws.onopen = () => {
      console.log('WebSocket connected, sending setup message');
      const setupMessage = {
        setup: {
          model: "models/gemini-2.0-flash-exp",
          tools: [{
            functionDeclarations: [{
              name: "get_weather",
              description: "Get current weather information for a city",
              parameters: {
                type: "OBJECT",
                properties: {
                  city: {
                    type: "STRING",
                    description: "The name of the city to get weather for"
                  }
                },
                required: ["city"]
              }
            }]
          },
          {
            codeExecution: {}
          },
          {
            googleSearch: {}
          }],
          generation_config: {
            response_modalities: ["audio"],
            speech_config: {
              voice_config: {
                prebuilt_voice_config: {
                  voice_name: "Aoede"
                }
              }
            }
          }
        }
      };
      ws.send(JSON.stringify(setupMessage));
    };

    ws.onerror = (error) => {
      console.error('WebSocket error:', error);
    };

    ws.onclose = (event) => {
      console.log('WebSocket closed:', event.code, event.reason);
    };

    ws.onmessage = async (event) => {
      try {
        console.log('Received WebSocket message');
        let wsResponse;
        if (event.data instanceof Blob) {
          console.log('Message is Blob, converting to text');
          const responseText = await event.data.text();
          wsResponse = JSON.parse(responseText);
        } else {
          wsResponse = JSON.parse(event.data);
        }

        console.log('Parsed response:', JSON.stringify(wsResponse, null, 2));

        if (wsResponse.setupComplete) {
          console.log('Setup complete, enabling mic button');
          document.getElementById('micButton').disabled = false;
        } else if (wsResponse.response?.media_chunks) {
          console.log('Received audio chunks:', wsResponse.response.media_chunks.length);
          for (const chunk of wsResponse.response.media_chunks) {
            await playAudioChunk(chunk.data);
          }
        } else if (wsResponse.toolCall) {
          console.log('Received tool call:', wsResponse.toolCall);
          const functionCalls = wsResponse.toolCall.functionCalls;
          const functionResponses = [];

          for (const call of functionCalls) {
            if (call.name === 'get_weather') {
              console.log('Executing weather function call for:', call.args.city);
              statusHandler.update('get_weather', { city: call.args.city, status: 'requesting' });
              const weather = await getWeather(call.args.city);
              console.log('Weather response:', weather);
              statusHandler.update('get_weather', { 
                city: call.args.city, 
                status: 'received',
                weather: weather 
              });

              functionResponses.push({
                id: call.id,
                name: call.name,
                response: {
                  result: {
                    object_value: weather
                  }
                }
              });
            }
          }

          if (functionResponses.length > 0) {
            const toolResponse = {
              tool_response: {
                function_responses: functionResponses
              }
            };
            console.log('Sending tool response:', toolResponse);
            ws.send(JSON.stringify(toolResponse));
          }
        } else if (wsResponse.serverContent) {
          console.log('Received server content');
          
          // Check for interruption
          if (wsResponse.serverContent.interrupted) {
            console.log('Gemini interrupted');
            isInterrupted = true;
            audioStreamer.stop();
            return;
          }

          // Process audio data if present
          if (wsResponse.serverContent.modelTurn?.parts?.[0]?.inlineData) {
            const audioData = wsResponse.serverContent.modelTurn.parts[0].inlineData.data;
            if (!audioStreamer.isPlaying) {
              console.log('Gemini speaking...');
            }
            await playAudioChunk(audioData);

            // Always send continue signal unless explicitly complete
            if (!wsResponse.serverContent.turnComplete) {
              sendContinueSignal();
            }
          }

          // Handle turn completion
          if (wsResponse.serverContent.turnComplete) {
            console.log('Gemini finished speaking');
            isInterrupted = false;  // Reset interruption state
            audioStreamer.complete();
          }
        } else if (wsResponse.error) {
          console.error('Server error:', wsResponse.error);
        } else {
          console.log('Unhandled response type');
        }
      } catch (error) {
        console.error('Error processing message:', error);
      }
    };
  </script>
</body>
</html>