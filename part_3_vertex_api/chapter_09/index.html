<!DOCTYPE html>
<!--
 Copyright 2024 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<html>
<head>
  <title>Gemini Audio-to-Audio WebSocket Demo (Vertex API)</title>
  <link rel="stylesheet" href="http://localhost:8000/shared/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
</head>
<body>
  <div class="header-section">
    <h1>Gemini Live Audio Chat (Vertex API)</h1>
    <p>This application demonstrates real-time audio-to-audio chat using the Gemini API and WebSockets. Speak into your microphone and receive audio responses in real time. The app uses the Web Audio API for capturing microphone input and playing back responses, with support for natural conversation flow and interruptions.</p>
  </div>

  <div class="input-container">
    <button id="micButton" onclick="toggleMicrophone()" disabled class="action-button">
      <span class="material-symbols-outlined">mic</span>
    </button>
  </div>
  <div id="output"></div>

  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>

  <!-- Load our API class -->
  <script src="http://localhost:8000/shared/gemini-live-api.js"></script>

  <!-- Then load our module code -->
  <script type="module">
    import { AudioRecorder } from 'http://localhost:8000/shared/audio-recorder.js';
    import { AudioStreamer } from 'http://localhost:8000/shared/audio-streamer.js';

    const output = document.getElementById('output');
    const PROXY_URL = 'ws://localhost:8081';
    const PROJECT_ID = '<YOUR_PROJECT_ID>';
    const LOCATION = 'us-central1';
    
    let audioContext;
    let audioStreamer;
    let audioRecorder;
    let isRecording = false;
    let initialized = false;
    let isInterrupted = false;
    let geminiAPI;  // Will be initialized with setup

    const setupConfig = {
      model: `projects/${PROJECT_ID}/locations/${LOCATION}/publishers/google/models/gemini-2.0-flash-exp`,
      generation_config: {
        response_modalities: ["audio"],
        speech_config: {
          voice_config: {
            prebuilt_voice_config: {
              voice_name: "Aoede"
            }
          }
        }
      }
    };

    // Initialize API and set up handlers
    function initializeAPI() {
      geminiAPI = new GeminiLiveAPI(PROXY_URL, true, setupConfig);
      setupGeminiHandlers();
    }

    // Initial setup
    initializeAPI();

    // Initialize audio when sending the first message
    async function ensureAudioInitialized() {
      if (!initialized) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        audioStreamer = new AudioStreamer(audioContext);
        await audioContext.resume();
        initialized = true;
        console.log('Audio context initialized:', audioContext.state);
      }
    }

    async function playAudioChunk(base64AudioChunk) {
      try {
        await ensureAudioInitialized();
        const arrayBuffer = base64ToArrayBuffer(base64AudioChunk);
        const uint8Array = new Uint8Array(arrayBuffer);
        audioStreamer.addPCM16(uint8Array);
        audioStreamer.resume();
      } catch (error) {
        console.error('Error queuing audio chunk:', error);
      }
    }

    async function startRecording() {
      try {
        await ensureAudioInitialized();

        // Reset state when starting new recording
        isInterrupted = false;
        audioStreamer.stop();  // Clean up any previous audio state

        // Reinitialize Gemini API if WebSocket is closed
        if (!geminiAPI || geminiAPI.ws.readyState !== WebSocket.OPEN) {
          initializeAPI();
          // Wait for the connection to be ready
          await new Promise((resolve, reject) => {
            const timeout = setTimeout(() => reject(new Error('Connection timeout')), 5000);
            geminiAPI.onSetupComplete = () => {
              clearTimeout(timeout);
              resolve();
              document.getElementById('micButton').disabled = false;
            };
          });
        }

        audioRecorder = new AudioRecorder();
        await audioRecorder.start();

        audioRecorder.on('data', (base64Data) => {
          geminiAPI.sendAudioChunk(base64Data);
        });

        logMessage('Recording started...');
        isRecording = true;
        document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error starting recording: ' + error.message);
      }
    }

    function stopRecording() {
      if (audioRecorder) {
        audioRecorder.stop();
        audioRecorder.off('data');
        logMessage('Recording stopped.');
        isRecording = false;
        document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">mic</span>';
        
        // Reset interruption state when stopping recording
        isInterrupted = false;
        
        // Send end message before closing
        geminiAPI.sendEndMessage();
      }
    }

    // Function to set up Gemini API event handlers
    function setupGeminiHandlers() {
      geminiAPI.onSetupComplete = () => {
        document.getElementById('micButton').disabled = false;
      };

      geminiAPI.onAudioData = async (audioData) => {
        if (!audioStreamer.isPlaying) {
          logMessage('Gemini: Speaking...');
        }
        await playAudioChunk(audioData);
      };

      geminiAPI.onInterrupted = () => {
        logMessage('Gemini: Interrupted');
        isInterrupted = true;
        audioStreamer.stop();
      };

      geminiAPI.onTurnComplete = () => {
        logMessage('Gemini: Finished speaking');
        isInterrupted = false;  // Reset interruption state
        audioStreamer.complete();
      };

      geminiAPI.onError = (message) => {
        logMessage(message);
      };

      geminiAPI.onClose = (event) => {
        logMessage(`Connection closed`);
      };
    }

    // Make toggleMicrophone available globally
    window.toggleMicrophone = function() {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    function base64ToArrayBuffer(base64) {
      const binaryString = atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    }

    function logMessage(message) {
      const messageElement = document.createElement('p');
      messageElement.textContent = message;
      output.appendChild(messageElement);
    }
  </script>
</body>
</html>